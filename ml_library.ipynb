{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data column transformation for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_col_transformation_regression(data, numerical_cols, categorical_cols, target, ohenc=0):\n",
    "    \"\"\"Function returns feature matrix & label array for given dataset\"\"\"\n",
    "    \n",
    "    # continuous numerical columns or 2 categoried column(0/1)\n",
    "    x_values = data.loc[:,numerical_cols].values\n",
    "    \n",
    "    # using one-hot-encoding for at least 3 categoried categorical column\n",
    "    one_hot_encode = OneHotEncoder()\n",
    "    if ohenc == 0:\n",
    "        new_columns = one_hot_encode.fit_transform(data.loc[:,categorical_cols]).toarray()\n",
    "    else:\n",
    "        new_columns = ohenc.transform(data.loc[:,categorical_cols]).toarray()\n",
    "    x_values = np.append(x_values, new_columns, axis=1)\n",
    "    \n",
    "    # target column\n",
    "    y_values = data[target].values\n",
    "    \n",
    "    return x_values, y_values, one_hot_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data, cols):\n",
    "    for col in cols:\n",
    "        quartile1 = data[col].quantile(0.25)\n",
    "        quartile3 = data[col].quantile(0.75)\n",
    "        inter_quartile_range = quartile3 - quartile1\n",
    "        outliers = data.loc[(data[col] < (quartile1 - 1.5 * inter_quartile_range)) |\\\n",
    "                            (data[col] > (quartile3 + 1.5 * inter_quartile_range))].index\n",
    "        data = data.drop(outliers)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting color map for classification for AdClick Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_colormap(x_set, y_set, classifier, title):\n",
    "    \"\"\"Function plots colormap showing classification using decision boundary\"\"\"\n",
    "    # createting grid of continuous points in given range of values from two columns of feature\n",
    "    # meshgrid returns matrices for their cartesian product after giving set of arrays \n",
    "    x1_grids, x2_grids = np.meshgrid(np.arange(x_set[:,0].min(), x_set[:,0].max(), 0.01), \n",
    "                            np.arange(x_set[:,1].min(), x_set[:,1].max(), 0.01))\n",
    "    \n",
    "    # we are patitioning data-ponts using decision boundary so coloring area on either side\n",
    "    # created feature matrix for area/continuous values from grid points from 2 features \n",
    "    x_continuous_values = np.array([x1_grids.flatten(), x2_grids.flatten()]).T\n",
    "    \n",
    "    # plotting area i.e continuous points & classification using regressor prediction \n",
    "    plt.contourf(x1_grids, x2_grids, classifier.predict(x_continuous_values).reshape(x1_grids.shape),\n",
    "                alpha=0.6, cmap= ListedColormap(('red', 'blue')))\n",
    "    \n",
    "    # \n",
    "    plt.xlim(x1_grids.min(), x1_grids.max())\n",
    "    plt.ylim(x2_grids.min(), x2_grids.max())\n",
    "    \n",
    "    # plotting actual classified data-points/observations with thier repective category\n",
    "    for j in np.unique(y_set):\n",
    "        plt.scatter(x_set[y_set == j, 0], x_set[y_set == j, 1],\n",
    "                   c=('red', 'blue')[j], label=j, s=6)\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Estimated Salary')     # labeling axes\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting CAP curve for classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cap_curve(actual_values, x_values, classifier, prob, x_label_name, y_label_name, classifier_model_name):\n",
    "    \"\"\"Function plots cumulative accuracy profile curve for given classifier model\"\"\"\n",
    "    \n",
    "    total = len(actual_values)\n",
    "    one_count = len(actual_values[actual_values==1])\n",
    "    \n",
    "    # Plotting random model\n",
    "    plt.plot([0, total], [0, one_count], ls='--', c='red', label='Random Model', alpha=0.7)\n",
    "    \n",
    "    # Plotting perfect model\n",
    "    plt.plot([0, one_count, total], [0, one_count, one_count], c='green', label='Perfect Model', alpha=0.4)\n",
    "    \n",
    "    # Plotting given classifier model\n",
    "    # getting predicted probabilities for default class among 0 & 1 , 1 is default class\n",
    "    default_cls_prob = classifier.predict_proba(x_values)[:,1]\n",
    "    \n",
    "    # sorting predicted proababilities for to get those earlier those are proabable to default class\n",
    "    sorted_predictions = list(sorted(zip(default_cls_prob, actual_values), reverse=True))\n",
    "\n",
    "   # creating list for accurate prediction of default class 1 if accurate prediction of default class else 0\n",
    "    accurate_one_predictions = []\n",
    "    for index in range(total):\n",
    "        if sorted_predictions[index][0] >= prob and sorted_predictions[index][1] == 1:\n",
    "            accurate_one_predictions.append(1)\n",
    "        else:\n",
    "            accurate_one_predictions.append(0)\n",
    "                \n",
    "    # creating values for both axes \n",
    "    x_axis_values = np.arange(total+1)\n",
    "    # taking cumulative sums for accurate predictions of default class\n",
    "    y_axis_values = np.cumsum([0] + accurate_one_predictions)\n",
    "    plt.plot(x_axis_values, y_axis_values, c='blue', label=classifier_model_name)\n",
    "    \n",
    "    # finding accuracy using CAP curve\n",
    "    mid_value = y_axis_values[int(total//2)]\n",
    "    print(f'Accuracy using CAP curve: {mid_value/one_count}')\n",
    "    \n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.legend()\n",
    "    plt.title('Cumulative Accuracy Profile')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function dividing a feature(string) to 8 different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_feature_column(data, feature):\n",
    "    \"\"\"Function returns 8 different features from 1 string value of feature\"\"\"\n",
    "    x_values = np.ones((1,8))\n",
    "    for value in data[feature]:\n",
    "        # creating numpy array of list of characters in each record & appending row at end\n",
    "        x_values = np.append(x_values, np.array(list(value)).reshape(1,8), axis=0)\n",
    "    return x_values[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleansing in NLP for english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "# import class method object for stemming i.e. getting root words\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# getting stopwords\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "corpus = []\n",
    "def get_corpus(data, col):\n",
    "    for index in range(len(data)):\n",
    "        text = re.sub('[^a-zA-Z]',' ',data[col][index])\n",
    "        text = text.lower()\n",
    "        text = text.split()\n",
    "        text = [ps.stem(word) for word in text if word not in set(stopwords.words('english'))] \n",
    "        text = \" \".join(text) \n",
    "        corpus.append(text) \n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating AUC while comparing different classifiation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# calculating area under curve\n",
    "def calculate_auc(model, fpr, tpr):\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print('AUC '+model+':', roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
