{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a machine learning  model for the dataset whether HIV-1 protease will cleave in the central position (between amino acids 4 and 5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://drive.google.com/open?id=1Vm_zruT2djYympL0lG6_l57kAEhF5hxH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>octamer</th>\n",
       "      <th>cleaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAKFERQ</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAMKRHG</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAMSSAI</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAKFERQH</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAKFESNF</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    octamer  cleaves\n",
       "0  AAAKFERQ       -1\n",
       "1  AAAMKRHG       -1\n",
       "2  AAAMSSAI       -1\n",
       "3  AAKFERQH       -1\n",
       "4  AAKFESNF       -1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir('/home/admin1/PycharmProjects/Machine Learning using libraries/Classification/Datasets')\n",
    "\n",
    "# reading dataset from different files & storing in pandas dataframe\n",
    "hiv_data = pd.read_table('746Data.txt', sep=',',names=['octamer','cleaves'])\n",
    "hiv_data = hiv_data.append(pd.read_table('1625Data.txt', sep=',',names=['octamer','cleaves']))\n",
    "hiv_data = hiv_data.append(pd.read_table('schillingData.txt', sep=',',names=['octamer','cleaves']))\n",
    "hiv_data = hiv_data.append(pd.read_table('impensData.txt', sep=',',names=['octamer','cleaves']))\n",
    "hiv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6590 entries, 0 to 946\n",
      "Data columns (total 2 columns):\n",
      "octamer    6590 non-null object\n",
      "cleaves    6590 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 154.5+ KB\n"
     ]
    }
   ],
   "source": [
    "hiv_data.info()                      # observing datatypes of columns & checking null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating different feature column for each character in octamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'octamer'\n",
    "label = 'cleaves'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_feature_column(data, feature):\n",
    "    x_values = np.ones((1,8))\n",
    "    for value in data[feature]:\n",
    "        # creating numpy array of list of characters in each record & appending row at end\n",
    "        x_values = np.append(x_values, np.array(list(value)).reshape(1,8), axis=0)\n",
    "    return x_values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['A', 'A', 'A', 'K', 'F', 'E', 'R', 'Q'],\n",
       "       ['A', 'A', 'A', 'M', 'K', 'R', 'H', 'G'],\n",
       "       ['A', 'A', 'A', 'M', 'S', 'S', 'A', 'I'],\n",
       "       ['A', 'A', 'K', 'F', 'E', 'R', 'Q', 'H'],\n",
       "       ['A', 'A', 'K', 'F', 'E', 'S', 'N', 'F'],\n",
       "       ['A', 'A', 'M', 'K', 'R', 'H', 'G', 'L'],\n",
       "       ['A', 'A', 'S', 'S', 'S', 'N', 'Y', 'C'],\n",
       "       ['A', 'A', 'V', 'L', 'A', 'E', 'A', 'M'],\n",
       "       ['A', 'C', 'E', 'G', 'N', 'P', 'Y', 'V'],\n",
       "       ['A', 'C', 'K', 'N', 'G', 'Q', 'T', 'N']], dtype='<U32')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values = separate_feature_column(hiv_data, feature)\n",
    "x_values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding for each column created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encode = OneHotEncoder()\n",
    "x_values = one_hot_encode.fit_transform(x_values)\n",
    "\n",
    "y_values = hiv_data[label].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting dataset into train set & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x_values, test_x_values, train_y_values, test_y_values = train_test_split(x_values, y_values, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(train_x_values, train_y_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing reusable objects into pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "file = open('/home/admin1/PycharmProjects/Machine Learning using libraries/DataProcessingHIV.pkl', 'wb')\n",
    "joblib.dump(feature, file)\n",
    "joblib.dump(label, file)\n",
    "joblib.dump(separate_feature_column, file)\n",
    "joblib.dump(one_hot_encode, file)\n",
    "file.close()\n",
    "\n",
    "file = open('LogisticModelHIV.pkl', 'wb')\n",
    "joblib.dump(classifier, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = classifier.predict(test_x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluatinig model against test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9438543247344461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print(f'Accuracy score: {accuracy_score(test_y_values, test_prediction)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[1016   27]\n",
      " [  47  228]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Confusion matrix:\\n {confusion_matrix(test_y_values, test_prediction)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
