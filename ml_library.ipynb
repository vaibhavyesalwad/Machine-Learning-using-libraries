{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data column transformation for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_col_transformation_regression(data, numerical_cols, categorical_cols, target, ohenc=0):\n",
    "    \"\"\"Function returns feature matrix & label array for given dataset\"\"\"\n",
    "    \n",
    "    # continuous numerical columns or 2 categoried column(0/1)\n",
    "    x_values = data.loc[:,numerical_cols].values\n",
    "    \n",
    "    # using one-hot-encoding for at least 3 categoried categorical column\n",
    "    one_hot_encode = OneHotEncoder()\n",
    "    if ohenc == 0:\n",
    "        new_columns = one_hot_encode.fit_transform(data.loc[:,categorical_cols]).toarray()\n",
    "    else:\n",
    "        new_columns = ohenc.transform(data.loc[:,categorical_cols]).toarray()\n",
    "    x_values = np.append(x_values, new_columns, axis=1)\n",
    "    \n",
    "    # target column\n",
    "    y_values = data[target].values\n",
    "    \n",
    "    return x_values, y_values, one_hot_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data, cols):\n",
    "    for col in cols:\n",
    "        quartile1 = data[col].quantile(0.25)\n",
    "        quartile3 = data[col].quantile(0.75)\n",
    "        inter_quartile_range = quartile3 - quartile1\n",
    "        outliers = data.loc[(data[col] < (quartile1 - 1.5 * inter_quartile_range)) |\\\n",
    "                            (data[col] > (quartile3 + 1.5 * inter_quartile_range))].index\n",
    "        data = data.drop(outliers)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Standardisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardising data (z-score normalisation)\n",
    "def standardisation(data):\n",
    "    for col in data.columns:\n",
    "        mean = data[col].mean()\n",
    "        std_deviation = data[col].std()\n",
    "        data[col] = (data[col] - mean)/std_deviation\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMax Normalisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling all columns in range 0-1 \n",
    "def min_max_normalisation(data):\n",
    "    for col in data.columns:\n",
    "        minimum = data[col].min()\n",
    "        maximum = data[col].max()\n",
    "        data[col] = (data[col] - minimum)/(maximum - minimum)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting dataset into train & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting 70 % dataset into train set & 30 % dataset into dataset into test set\n",
    "def splitting_dataset(data):\n",
    "    train = data.sample(frac=0.7, random_state=3)   # selecting random 0.7 fraction of dataset as train set   \n",
    "    # chossing different random state will give different random rows\n",
    "    test = data.drop(train.index)            # selecting remaining i.e. 30% as test set\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorising functions for different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorising predicted values of logistic regression\n",
    "def categorise_logistic(y_values):\n",
    "    return np.where(y_values >= 0.5, 1, 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise_knn(y_values):\n",
    "    return np.where(y_values == True, 1, 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root mean squared error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_sqr_error(predicted_values, actual_values):\n",
    "    mean_sqr_error = ((predicted_values - actual_values)**2).mean()        # mean squared error\n",
    "    return np.sqrt(mean_sqr_error)              # root mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R^2 score (Coeff of Determination) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_sqr_score(predicted_values, actual_values):    \n",
    "    sum_sqr_errors = ((predicted_values - actual_values)**2).sum()        # sum of square of residuals/errors\n",
    "    sum_sqr_deviations = ((actual_values - actual_values.mean())**2).sum()  # sum of squares of actual deviations\n",
    "    return (1 - sum_sqr_errors/sum_sqr_deviations)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_regression(predicted_values, actual_values):\n",
    "    total_error = abs(predicted_values - actual_values)/actual_values\n",
    "    return (1- total_error.mean())*100        # percentage of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_classification(predicted_values, actual_values):\n",
    "    return (predicted_values == actual_values).mean()*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
