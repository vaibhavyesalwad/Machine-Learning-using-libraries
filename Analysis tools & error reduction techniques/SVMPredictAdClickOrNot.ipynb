{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a machine learning model to predict user will click the ad or not based on his experience and estimated salary for a given dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://drive.google.com/open?id=1I8KsCufEa47XvzrkxhntEWSy1Su0E0NY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('/home/admin1/PycharmProjects/Machine Learning using libraries/Classification/Datasets & pickled objects/')\n",
    "import sys\n",
    "sys.path.append('/home/admin1/PycharmProjects/Machine Learning using libraries/')\n",
    "from ipynb.fs.full.ml_library import *\n",
    "\n",
    "# reading dataset from file & storing it as pandas dataframe\n",
    "social_network_data = pd.read_csv('Social_Network_Ads.csv')\n",
    "social_network_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using already done preprocessing steps from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "file = open('DataProcessingAdClick.pkl', 'rb')\n",
    "features = joblib.load(file)\n",
    "label = joblib.load(file)\n",
    "sc_x = joblib.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating out feature colums & label column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = social_network_data.loc[:,features].values\n",
    "y_values = social_network_data.loc[:,label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = sc_x.transform(x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting dataset into train set & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "train_x_values, test_x_values, train_y_values, test_y_values = train_test_split(x_values, y_values, train_size=0.8, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Support Vector Machine (SVM) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "# defining different train set sizes\n",
    "train_sizes= [10,40,80,140,220,320]\n",
    "\n",
    "# creating x-axis values & y-axis values for learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=classifier, X=x_values, y=y_values,\n",
    "                                                        train_sizes=train_sizes, scoring='accuracy', cv=10)\n",
    "# taking mean for each cross-validation\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "test_scores_mean =  test_scores.mean(axis=1)\n",
    "\n",
    "# plotting two line graphs for different test sizes \n",
    "plt.style.use('seaborn')\n",
    "plt.plot(train_sizes, train_scores_mean, label='Train score')\n",
    "plt.plot(train_sizes, test_scores_mean, label='Test score')\n",
    "plt.xlabel('Train size')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Learning curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need whole train set for training of classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting optimal hyperparametrs using gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hypermeters in list of dictionaries initially & changing these to optimal values after running this block of code\n",
    "parameters = [{'C':[.1,.2,.3,.5,.6], 'kernel': ['rbf'], 'gamma':[.1,.2,.3]},\n",
    "             {'C':[1,10,100,1000], 'kernel': ['linear'], 'gamma':[.1,.01,.001]},\n",
    "             {'C':[1,10,100,1000], 'kernel': ['poly'], 'gamma':[.1,.01,.001]}]\n",
    "\n",
    "# creating grid search object with paramters to try & 10-fold cross validation\n",
    "grid_search = GridSearchCV(estimator=classifier, param_grid=parameters, scoring='accuracy', cv=10)\n",
    "\n",
    "# fitting classifier model for given parameters for trial\n",
    "grid_search = grid_search.fit(train_x_values, train_y_values)\n",
    "\n",
    "# finding best accuracy & best parameters\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy, best_parameters\n",
    "\n",
    "# unpacking hypermeters' optimal values to variable further will be feed to classifier model\n",
    "C, gamma, kernel = best_parameters.values()\n",
    "best_parameters, (C, gamma, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(kernel=kernel, probability=True, C=C, gamma=gamma, random_state=0)\n",
    "classifier.fit(x_values, y_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking cross-validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(estimator=classifier, X=x_values, y=y_values, cv=10)\n",
    "accuracies, accuracies.mean(), accuracies.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing essential objects into pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "file = open('SVMModelAdClick.pkl', 'wb')\n",
    "joblib.dump(classifier, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = classifier.predict(test_x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model against test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "print(f'Confusion matrix:\\n {confusion_matrix(test_y_values, test_prediction)}')\n",
    "print(f'\\nClassification report:\\n {classification_report(test_y_values, test_prediction)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting colormap for  classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 (blue) represents user purchased &  0 (red) represents user not purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_colormap(train_x_values, train_y_values, classifier,'Train set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_colormap(test_x_values, test_y_values, classifier,'Test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting CAP (Cumulative Accuracy Profile) curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 0.5   # it is default threshold probability for classification in sklearn\n",
    "plot_cap_curve(test_y_values, test_x_values, classifier, prob, 'Total number of users shown ad', 'Purchased', 'SVM Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we want precision in prediction of accurate potential users those will purchase (high precision score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob = classifier.predict_proba(test_x_values)[:,1]\n",
    "prob = 0.7\n",
    "test_prediction = np.where(test_prob > prob, 1, 0)\n",
    "print(f'Confusion matrix:\\n {confusion_matrix(test_y_values, test_prediction)}')\n",
    "print(f'Classification report:\\n {classification_report(test_y_values, test_prediction)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting CAP curve for high precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cap_curve(test_y_values, test_x_values, classifier, prob, 'Total number of users shown ad', 'Purchased', 'Logistic Regression Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we want to miss out minimum potential user who will purchase (high recall score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 0.1\n",
    "test_prediction = np.where(test_prob > prob, 1, 0)\n",
    "print(f'Confusion matrix:\\n {confusion_matrix(test_y_values, test_prediction)}')\n",
    "print(f'Classification report:\\n {classification_report(test_y_values, test_prediction)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting CAP curve for high recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cap_curve(test_y_values, test_x_values, classifier, prob, 'Total number of users shown ad', 'Purchased', 'Logistic Regression Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating area under curve\n",
    "def calculate_auc(model, fpr, tpr):\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print('AUC '+model+':', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# finding probability for default class 1\n",
    "test_predicted_prob_svm = classifier.predict_proba(test_x_values)[:,1]\n",
    "\n",
    "# getting x-axis & y-axis values \n",
    "fpr_svm, tpr_svm, _ = roc_curve(test_y_values, test_predicted_prob_svm)\n",
    "\n",
    "calculate_auc('SVM', fpr_svm, tpr_svm)\n",
    "# Plotting ROC curve\n",
    "plt.plot([0,1],[0,1], 'r--')\n",
    "plt.plot(fpr_svm, tpr_svm, label='SVM')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing different classification models using ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pickled objects of different classificationmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "file = open('LogisticModelAdClick.pkl', 'rb')\n",
    "logistic_classifier = joblib.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('KNNModelAdClick.pkl', 'rb')\n",
    "KNN_classifier = joblib.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('DCTModelAdClick.pkl', 'rb')\n",
    "DCT_classifier = joblib.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('RFModelAdClick.pkl', 'rb')\n",
    "RF_classifier = joblib.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('GaussianNBModelAdClick.pkl', 'rb')\n",
    "GaussianNB_classifier = joblib.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing different classification model object in list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [logistic_classifier, KNN_classifier, classifier, DCT_classifier, RF_classifier, GaussianNB_classifier]\n",
    "classifier_names = ['Logistic', 'KNN', 'SVM', 'DecisionTree', 'RandomForest', 'GaussianNaiveBayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding probability for default class 1\n",
    "    \n",
    "test_predicted_probs = [classifier.predict_proba(test_x_values)[:,1] for classifier in classifiers]\n",
    "\n",
    "# Plotting ROC curve & calculating AUCs\n",
    "for index in range(len(classifiers)):\n",
    "    fpr, tpr, _ = roc_curve(test_y_values, test_predicted_probs[index])\n",
    "    calculate_auc(classifier_names[index], fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=classifier_names[index])\n",
    "\n",
    "plt.plot([0,1],[0,1], 'r--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Comparison betn different Classication Models for Ad Click dataset',fontdict={'fontsize':15})\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
